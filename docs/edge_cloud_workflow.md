# 端云协同实验流程

本说明帮助你把手机端推理与云端大模型服务结合，形成可量化的实验闭环。

## 1. 任务建模

1. 选择基准数据集（如对话摘要、问答、安全过滤），将每条样本转成 JSON：`{"id", "prompt", "reference"}`。
2. 为每条样本构建 DAG：节点包含分配给端侧或云端的子任务、预估耗时、依赖关系。
3. 根据数据敏感度、上下文长度、实时性决定节点执行位置（端/云）。

## 2. 执行流程

1. 端侧调度器按 DAG 执行任务：本地模型 `predict`、网络请求云端 API、缓存结果。
2. 记录日志（时间戳、电量、网络字节数）并输出 JSONL：
   ```json
   {
     "id": "sample-001",
     "node": "edge-summary",
     "start_ms": 123,
     "end_ms": 456,
     "energy_mwh": 5.2,
     "bytes_up": 2000,
     "bytes_down": 1800,
     "output": "..."
   }
   ```
3. 云端返回结果后继续触发依赖节点，直至完成整条任务。

## 3. 指标计算

1. PC 端运行 `experiments/mobile_benchmark/benchmark_runner.py`（原仓库）或自行编写评测脚本，对输出进行 ROUGE / EM / Accuracy 计算。
2. 使用 `id` 对齐手机日志与评测结果，汇总成表格：`策略、质量、延迟、能耗、流量`。
3. 绘制 `延迟-质量`、`能耗-质量` 的 Pareto 前沿，观察端云协同收益。

## 4. 调度策略实验

可比较以下策略：

- **端侧独立**：全部子任务在手机完成。
- **纯云端**：端侧仅负责请求，云端完成全部推理。
- **协同调度**：端侧先执行轻量任务，云端处理复杂部分。

附加策略：

- 基于节点深度/Slack 的优先级调度（参考 HEFT/List Scheduling）。
- 任务聚类：按模型类型、耗时、敏感度分组后批量处理。
- 数据缓存：对重复子任务共享缓存结果。

## 5. 报告模板

建议为每轮实验整理如下内容：

1. **实验设置**：模型版本、量化格式、设备型号、云端配置。
2. **指标表**：策略 × (平均延迟、P95 延迟、ROUGE、能耗、流量)。
3. **可视化**：折线图、散点图展示性能与质量权衡。
4. **观察总结**：端侧瓶颈、网络开销、冷启动时延等。
5. **改进方向**：优化调度、模型压缩、网络协商方案。

---

结合此流程与 `docs/perf_tuning.md`、`android_setup.md`、`ios_setup.md` 即可系统地完成端云协同的验证工作。*** End Patch
